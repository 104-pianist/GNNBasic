{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cora():\n",
    "    def __init__(self, path, dataset):\n",
    "        self.path = path\n",
    "        self.dataset = dataset\n",
    "\n",
    "    def process_data(self):\n",
    "        id_feature_label = np.genfromtxt('{path}{dataset}.content'\n",
    "                                    .format(path=self.path, dataset=self.dataset)\n",
    "                                    , dtype=np.dtype(str))\n",
    "        \n",
    "        feature = sp.csc_matrix(id_feature_label[:, 1:-1], dtype=np.float32)\n",
    "\n",
    "        label = np.array(pd.get_dummies(id_feature_label[:, -1]), dtype=np.int32)\n",
    "\n",
    "        adj = self.build_adjcency_matrix(id_feature_label, label)\n",
    "\n",
    "        adj = adj + adj.multiply(adj.T > adj) - adj.multiply(adj.T > adj)\n",
    "\n",
    "        def normalize(adj):\n",
    "            adj += sp.eye(adj.shape[0])\n",
    "            row_sum = np.array(adj.sum(1))\n",
    "            d_hat = np.power(row_sum, -0.5).flatten()\n",
    "            d_hat[np.isinf(d_hat)] = 0.\n",
    "            d_hat = sp.diags(d_hat)\n",
    "            return d_hat.dot(adj).dot(d_hat)\n",
    "        \n",
    "        adj = normalize(adj)\n",
    "\n",
    "        index_train = range(140)\n",
    "        index_val = range(140, 640)\n",
    "        index_test = range(1708, 2708)\n",
    "\n",
    "        def sample_mask(index, length):\n",
    "            mask = np.zeros(length)\n",
    "            mask[index] = 1\n",
    "            return np.array(mask, dtype=np.bool_)\n",
    "        \n",
    "        length = label.shape[0]\n",
    "\n",
    "        train_mask = sample_mask(index_train, length)\n",
    "        val_mask = sample_mask(index_val, length)\n",
    "        test_mask = sample_mask(index_test, length)\n",
    "\n",
    "        # print(feature.shape, type(feature))\n",
    "        # print(label.shape, type(label))\n",
    "        # print(adj.shape, type(adj))\n",
    "        # print(train_mask.shape, type(train_mask))\n",
    "        # print(val_mask.shape, type(val_mask))\n",
    "        # print(test_mask.shape, type(test_mask))\n",
    "\n",
    "        feature = torch.FloatTensor(np.array(feature.todense()))\n",
    "        label = torch.LongTensor(np.where(label)[1])\n",
    "\n",
    "        def sparse_mx_to_torch_sparse_tensor(sparse_mx):\n",
    "            \"\"\"Convert a scipy sparse matrix to a torch sparse tensor.\"\"\"\n",
    "            sparse_mx = sparse_mx.tocoo().astype(np.float32)\n",
    "            indices = torch.from_numpy(\n",
    "                np.vstack((sparse_mx.row, sparse_mx.col)).astype(np.int64))\n",
    "            values = torch.from_numpy(sparse_mx.data)\n",
    "            shape = torch.Size(sparse_mx.shape)\n",
    "            return torch.sparse.FloatTensor(indices, values, shape)\n",
    "\n",
    "        adj = sparse_mx_to_torch_sparse_tensor(adj)\n",
    "\n",
    "        train_mask = torch.from_numpy(train_mask)\n",
    "        val_mask = torch.from_numpy(val_mask)\n",
    "        test_mask = torch.from_numpy(test_mask)\n",
    "    \n",
    "        return feature, label, adj, train_mask, val_mask, test_mask\n",
    "    \n",
    "\n",
    "    def build_adjcency_matrix(self, id_feature_label, label):\n",
    "        id = np.array(id_feature_label[:, 0], dtype=np.int32)\n",
    "        id_map = {j: i for i, j in enumerate(id)}\n",
    "\n",
    "        edges = np.genfromtxt(\"{path}{dataset}.cites\".format(path=self.path, dataset=self.dataset)\n",
    "                                , dtype=np.int32)\n",
    "\n",
    "        edges_order_by_id = np.array(list(map(id_map.get, edges.flatten())), dtype=np.int32) \\\n",
    "                            .reshape(edges.shape)\n",
    "\n",
    "        row = edges_order_by_id[:, 0]\n",
    "        col = edges_order_by_id[:, 1]\n",
    "        data = np.ones(edges_order_by_id.shape[0])\n",
    "        adj = sp.coo_matrix((data, (row, col))\n",
    "                                        , shape=(label.shape[0], label.shape[0])\n",
    "                                        , dtype=np.float32)\n",
    "        return adj\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]),\n",
       " tensor([2, 5, 4,  ..., 1, 0, 2]),\n",
       " tensor(indices=tensor([[   0,   14,  258,  ..., 2705, 2706, 2707],\n",
       "                        [   0,    0,    0,  ..., 2705, 2706, 2707]]),\n",
       "        values=tensor([0.2500, 0.1118, 0.1443,  ..., 1.0000, 0.2000, 0.2500]),\n",
       "        size=(2708, 2708), nnz=8137, layout=torch.sparse_coo),\n",
       " tensor([ True,  True,  True,  ..., False, False, False]),\n",
       " tensor([False, False, False,  ..., False, False, False]),\n",
       " tensor([False, False, False,  ...,  True,  True,  True]))"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cora = Cora(path='../../data_processing/data/cora/', dataset='cora')\n",
    "cora.process_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphConvolution(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, use_bias=True):\n",
    "        super(GraphConvolution, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.use_bias = use_bias\n",
    "        self.weight = nn.Parameter(torch.Tensor(input_dim, output_dim))\n",
    "        if self.use_bias:\n",
    "            self.bias = nn.Parameter(torch.Tensor(output_dim))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "        self.reset_parameters()\n",
    "    \n",
    "    def reset_parameters(self):\n",
    "        init.kaiming_normal_(self.weight)\n",
    "        if self.use_bias:\n",
    "            init.zeros_(self.bias)\n",
    "    \n",
    "\n",
    "    def forward(self, adjacency, input_feature):\n",
    "        support = torch.mm(input_feature, self.weight)\n",
    "        output = torch.sparse.mm(adjacency, support)\n",
    "        if self.use_bias:\n",
    "            return output + self.use_bias\n",
    "        else:\n",
    "            return output\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + ' (' \\\n",
    "            + str(self.input_dim) + ' -> ' \\\n",
    "            + str(self.output_dim) + ')'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(nn.Module):\n",
    "    def __init__(self, input_dim=1433):\n",
    "        super(GCN, self).__init__()\n",
    "        self.gcn1 = GCN(input_dim, 16)\n",
    "        self.gcn2 = GCN(16, 7)\n",
    "\n",
    "    def forward(self, adjacency, feature):\n",
    "        h = F.relu(self.gcn1(adjacency, feature))\n",
    "        logits = self.gcn2(adjacency, h)\n",
    "        return logits\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义超参数\n",
    "LEARNING_RATE = 0.1 # 学习率\n",
    "WEIGHT_DACAY = 5e-4 # 权重衰减\n",
    "EPOCHS = 200\n",
    "DEVICE = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2708, 1433]) <class 'torch.Tensor'>\n",
      "torch.Size([2708]) <class 'torch.Tensor'>\n",
      "torch.Size([2708, 2708]) <class 'torch.Tensor'>\n",
      "torch.Size([2708]) <class 'torch.Tensor'>\n",
      "torch.Size([2708]) <class 'torch.Tensor'>\n",
      "torch.Size([2708]) <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "feature, label, adj, train_mask, val_mask, test_mask = Cora(path='../../data_processing/data/cora/', dataset='cora').process_data()\n",
    "\n",
    "print(feature.shape, type(feature))\n",
    "print(label.shape, type(label))\n",
    "print(adj.shape, type(adj))\n",
    "print(train_mask.shape, type(train_mask))\n",
    "print(val_mask.shape, type(val_mask))\n",
    "print(test_mask.shape, type(test_mask))\n",
    "\n",
    "input_dim = 1433\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() takes from 1 to 2 positional arguments but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-115-97633a4c5d17>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGCN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m optimizer = optim.Adam(model.parameters(), \n\u001b[0;32m      4\u001b[0m                        \u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mLEARNING_RATE\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                        weight_decay=WEIGHT_DACAY)\n",
      "\u001b[1;32m<ipython-input-112-c6d611282496>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, input_dim)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_dim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1433\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mGCN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgcn1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGCN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m16\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgcn2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGCN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m7\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() takes from 1 to 2 positional arguments but 3 were given"
     ]
    }
   ],
   "source": [
    "model = GCN(input_dim).to(DEVICE)\n",
    "criterion = nn.CrossEntropyLoss().to(DEVICE)\n",
    "optimizer = optim.Adam(model.parameters(), \n",
    "                       lr=LEARNING_RATE, \n",
    "                       weight_decay=WEIGHT_DACAY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "73e03da126b73bfff3642ec5261d56fa25c444ea595de51041687efaa60dda41"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
